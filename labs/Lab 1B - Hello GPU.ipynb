{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 1B - Hello GPU.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yKcbbrwlarek","colab_type":"text"},"source":["# Hello, GPU!\n","\n","The graphics processing unit (GPU) is a powerful hardware acceleration card originally developed for 3D graphics. It is also ideal for various parallelizable workloads, common in machine learning and deep learning.\n","\n","![](https://deeplearning-mat.s3-ap-southeast-1.amazonaws.com/t4.jpg)\n","\n","The [**NVIDIA Tesla T4 GPU**](https://www.nvidia.com/en-sg/data-center/tesla-t4/), available for free on Google Colab, is fantastic for many small-mid size machine learning and deep learning problems. With 16GB of GDDR6 memory and up to 65 TLFOPS of mixed precision performance, it has better performance than most laptop and even desktop GPUs. \n","\n","**Important Note**\n","\n","Due to capacity issues, Google Colab might allocate you the older K80 GPU instead. If you encounter that, and require a better GPU (e.g. to use features such as Mixed Precision, or software frameworks like [RAPIDS](https://rapids.ai/)), you can try to get re-assigned a GPU by going to the menu bar and selecting **Runtime > Reset All Runtimes**.\n","\n"]},{"cell_type":"code","metadata":{"id":"apV6X-9Karem","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":305},"outputId":"455bdfe4-f593-4ddb-fb92-24f2d77c6a96","executionInfo":{"status":"ok","timestamp":1564473830294,"user_tz":-480,"elapsed":2537,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh4.googleusercontent.com/-dGSoF3PTUms/AAAAAAAAAAI/AAAAAAAAEjo/onM3a4Ivxls/s64/photo.jpg","userId":"03413426750796061565"}}},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Jul 30 08:03:49 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   67C    P0    30W /  70W |   7305MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tS5MdBSBaret","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":305},"outputId":"bef809ab-d76c-4b9f-ee03-9fda2d7ee6cd","executionInfo":{"status":"ok","timestamp":1564473839368,"user_tz":-480,"elapsed":11608,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh4.googleusercontent.com/-dGSoF3PTUms/AAAAAAAAAAI/AAAAAAAAEjo/onM3a4Ivxls/s64/photo.jpg","userId":"03413426750796061565"}}},"source":["!pip install gpustat\n","!gpustat"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting gpustat\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 3.9MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.12.0)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat) (7.352.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat) (5.4.8)\n","Collecting blessings>=1.6 (from gpustat)\n","  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n","Building wheels for collected packages: gpustat\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n","Successfully built gpustat\n","Installing collected packages: blessings, gpustat\n","Successfully installed blessings-1.7 gpustat-0.6.0\n","\u001b[1m\u001b[37m6cf4152b39a8       \u001b[m  Tue Jul 30 08:03:57 2019  \u001b[1m\u001b[30m410.79\u001b[m\n","\u001b[36m[0]\u001b[m \u001b[34mTesla T4        \u001b[m |\u001b[1m\u001b[31m 67'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 7305\u001b[m / \u001b[33m15079\u001b[m MB |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kXpFDB8darex","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":503},"outputId":"058bf3fb-4df4-4ea3-d312-39d2996a5377","executionInfo":{"status":"ok","timestamp":1564473842018,"user_tz":-480,"elapsed":14258,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh4.googleusercontent.com/-dGSoF3PTUms/AAAAAAAAAAI/AAAAAAAAEjo/onM3a4Ivxls/s64/photo.jpg","userId":"03413426750796061565"}}},"source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","\n","device_lib.list_local_devices()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 3241160274348985239, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 4799257578157049347\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 1134985600563227530\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 7625444557\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 14642726206955522544\n"," physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"]},"metadata":{"tags":[]},"execution_count":3}]}]}