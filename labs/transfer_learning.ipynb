{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_learning.ipynb","provenance":[{"file_id":"1z1U96GN66FkYS-vVtx3fl-Lyvr_TiS47","timestamp":1561810535270},{"file_id":"1bqE06VfVpNXtL0We-fbBEFO50BW450AJ","timestamp":1555169281814}],"collapsed_sections":["h7R_FcIPA1Ko"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"h7R_FcIPA1Ko","colab_type":"text"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"HTqhOE9jWQRc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"d77d4d0d-d43d-4823-bd7b-1a7c253aad39","executionInfo":{"status":"ok","timestamp":1577688609465,"user_tz":-480,"elapsed":7336,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCS8LwI0k0t2vkujQUBYfPPAo7627gWEnmKxe1ocA=s64","userId":"03413426750796061565"}}},"source":["!pip uninstall tensorflow -yq\n","!pip install tensorflow-gpu>=2.0 gpustat -qU"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nOug94VRWWd0","colab_type":"code","colab":{}},"source":["import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","import tensorflow\n","\n","import tensorflow.compat.v2 as tf\n","import tensorflow.keras.layers as layers\n","import tensorflow_datasets as tfds"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oEi36ou7KySx","colab_type":"text"},"source":["# Transfer Learning with Keras"]},{"cell_type":"markdown","metadata":{"id":"WYijcApeY5R4","colab_type":"text"},"source":["In this notebook, we are going to be doing image classification on the [Kaggle \"Cats vs Dogs\" dataset](https://www.kaggle.com/c/dogs-vs-cats).\n","\n","However, we are not going to be training the model from scratch. Instead, we will be leveraging **transfer learning** to reduce the amount of time needed to train a very high accuracy model on a relatively small dataset. Transfer learning works by taking a model that has been trained on a much larger dataset (e.g. ImageNet), and then fine-tuning it for another task. This works because much of the model learns features that apply to the same type images in general (e.g. RGB photographs). \n","\n","This notebook demonstrates a typical example of transfer learning where we take a model that has been trained on ImageNet, and fine-tune it for our own task."]},{"cell_type":"code","metadata":{"id":"KEiB77wqK1vy","colab_type":"code","outputId":"2ca764f6-7af1-4786-ce7e-0486d88893d9","executionInfo":{"status":"ok","timestamp":1577688615874,"user_tz":-480,"elapsed":13723,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCS8LwI0k0t2vkujQUBYfPPAo7627gWEnmKxe1ocA=s64","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["!gpustat"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[1m\u001b[37m7875b60ed81f           \u001b[m  Mon Dec 30 06:50:13 2019  \u001b[1m\u001b[30m418.67\u001b[m\n","\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 43'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m16280\u001b[m MB |\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AZieFWCpLUtO","colab_type":"text"},"source":["## Construct Input Pipeline"]},{"cell_type":"markdown","metadata":{"id":"eVgB1lohZu2l","colab_type":"text"},"source":["This section demonstrates how to build a high-performance input pipeline for feeding in training and evaluation data into the model."]},{"cell_type":"markdown","metadata":{"id":"z4O-FO1UaYeY","colab_type":"text"},"source":["### Load Dataset using TensorFlow Datasets\n","\n","\"Cats vs Dogs\" is not a standard research dataset, and is not found in `tf.keras.datasets` like the more common MNIST or CIFAR10. Fortunately, **TensorFlow Datasets** not only contains this dataset, but also many others. \n","\n","When we load datasets with TensorFlow Datasets, we get [`tf.data.Dataset`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset) objects. This means we automatically take advantage of high performance `tf.data` primitives to create highly-optimized, efficient input pipelines that result in better utilization of our hardware accelerators, such as GPUs or TPUs that might otherwise be constantly \"waiting\" for data from the CPU. This is important because hardware accelerators for deep learning are so fast, the speed at which we can feed images into the accelerator is usually a significant bottleneck. \n","\n","Using `tf.data` is a best practice (especially for reading large datasets). You can read more about using tf.data at the following links:\n","\n","* https://www.tensorflow.org/beta/guide/data\n","* https://www.tensorflow.org/guide/performance/datasets"]},{"cell_type":"code","metadata":{"id":"kf0vStKoaYCH","colab_type":"code","outputId":"a079377c-f0a4-4e66-ddaa-20ce8e74f442","executionInfo":{"status":"ok","timestamp":1577688616376,"user_tz":-480,"elapsed":14214,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCS8LwI0k0t2vkujQUBYfPPAo7627gWEnmKxe1ocA=s64","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# define train-validation-test split\n","splits = tfds.Split.TRAIN.subsplit(weighted=(8, 1, 1))\n","\n","# load dataset with corresponding split\n","(raw_train, raw_validation, raw_test), info = tfds.load(\"cats_vs_dogs\",\n","                                                        split=list(splits),\n","                                                        with_info=True,\n","                                                        as_supervised=True)\n","\n","num_examples = info.splits[\"train\"].num_examples\n","num_train = int(num_examples * 0.8)\n","num_val = int(num_examples * 0.1)\n","num_test = int(num_examples * 0.1)\n","\n","print(\"Split:\", num_train, num_val, num_test)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Split: 18609 2326 2326\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WOy7hAFtcnaW","colab_type":"text"},"source":["### Build `tf.data` Pipeline"]},{"cell_type":"code","metadata":{"id":"6Ob-z76OwFQL","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","IMG_SIZE = (256, 256)\n","\n","@tf.function\n","def format_example(image, label):\n","    \"\"\"\n","    This function will run as part of a tf.data pipeline.\n","    It is reponsible for resizing and normalizing the input images.\n","    \"\"\"\n","    image = tf.cast(image, tf.float32)\n","    image = tf.image.resize(image, IMG_SIZE)\n","    image = (image/127.5) - 1\n","    return image, label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMD5_KhndBJK","colab_type":"text"},"source":["**Input Pipeline for Train Images**"]},{"cell_type":"code","metadata":{"id":"iMO6uEZPKmc-","colab_type":"code","colab":{}},"source":["train = raw_train.shuffle(4096)\n","train = train.repeat(count=-1)\n","train = train.map(format_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","train = train.batch(BATCH_SIZE)\n","train = train.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tgvLwbffdL9-","colab_type":"text"},"source":["**Input Pipeline for Validation and Test Images**\n","\n","We remove some unnecessary steps (like shuffling) and increase the batch size for faster inferencing."]},{"cell_type":"code","metadata":{"id":"bPxsljSkdMKC","colab_type":"code","colab":{}},"source":["val = raw_validation.repeat(count=-1)\n","val = val.map(format_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","val = val.batch(BATCH_SIZE*2)\n","val = val.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","test = raw_test.repeat(count=-1)\n","test = test.map(format_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","test = test.batch(BATCH_SIZE*2)\n","test = test.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUB3aSlaN0iH","colab_type":"text"},"source":["## Construct the Model"]},{"cell_type":"code","metadata":{"id":"7h0pyAF0L_EX","colab_type":"code","colab":{}},"source":["# you could also use other models like the following ResNet 50:\n","# from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmMHAwp688E-","colab_type":"code","outputId":"3644fe1d-49e5-47c6-967d-7544b548b7b2","executionInfo":{"status":"ok","timestamp":1577688619574,"user_tz":-480,"elapsed":17330,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCS8LwI0k0t2vkujQUBYfPPAo7627gWEnmKxe1ocA=s64","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["input_layer = layers.Input(shape=(IMG_SIZE[0],IMG_SIZE[1],3,))\n","\n","base = MobileNetV2(input_tensor=input_layer, include_top=False, weights='imagenet')\n","\n","base.trainable = False\n","\n","x = base.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.2)(x)\n","preds = layers.Dense(2, activation=\"softmax\")(x)\n","\n","model = tf.keras.models.Model(inputs=input_layer, outputs=preds)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  warnings.warn('`input_shape` is undefined or non-square, '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"u90VRx_5NiS6","colab_type":"code","colab":{}},"source":["opt = tf.keras.optimizers.Adam()\n","\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=opt,\n","              metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CpB3PSWgqTLw","colab_type":"text"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"id":"2zkA41zrd4YJ","colab_type":"code","outputId":"6bd9ba3c-24a6-44ca-979b-1d710057b602","executionInfo":{"status":"ok","timestamp":1577688728522,"user_tz":-480,"elapsed":126258,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCS8LwI0k0t2vkujQUBYfPPAo7627gWEnmKxe1ocA=s64","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["train_steps = num_train//BATCH_SIZE\n","valid_steps = num_val//(BATCH_SIZE*2)\n","\n","model.fit(train, validation_data=val,\n","          validation_steps=valid_steps,\n","          steps_per_epoch=train_steps,\n","          epochs=2)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Train for 290 steps, validate for 18 steps\n","Epoch 1/2\n","290/290 [==============================] - 58s 201ms/step - loss: 0.1507 - accuracy: 0.9396 - val_loss: 0.1010 - val_accuracy: 0.9614\n","Epoch 2/2\n","290/290 [==============================] - 50s 173ms/step - loss: 0.0894 - accuracy: 0.9657 - val_loss: 0.1019 - val_accuracy: 0.9640\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f3fe3041198>"]},"metadata":{"tags":[]},"execution_count":11}]}]}