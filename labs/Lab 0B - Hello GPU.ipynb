{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 0B - Hello GPU.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yKcbbrwlarek","colab_type":"text"},"source":["# Hello, GPU!\n","\n","The graphics processing unit (GPU) is a powerful hardware acceleration card originally developed for 3D graphics. It is also ideal for various parallelizable workloads, common in machine learning and deep learning.\n","\n","![](https://deeplearning-mat.s3-ap-southeast-1.amazonaws.com/t4.jpg)\n","\n","The [**NVIDIA Tesla T4 GPU**](https://www.nvidia.com/en-sg/data-center/tesla-t4/), available for free on Google Colab, is fantastic for many small-mid size machine learning and deep learning problems. With 16GB of GDDR6 memory and up to 65 TLFOPS of mixed precision performance, it has better performance than most laptop and even desktop GPUs. \n","\n","**Important Note**\n","\n","Due to capacity issues, Google Colab might allocate you the older K80 GPU instead. If you encounter that, and require a better GPU (e.g. to use features such as Mixed Precision, or software frameworks like [RAPIDS](https://rapids.ai/)), you can try to get re-assigned a GPU by going to the menu bar and selecting **Runtime > Reset All Runtimes**.\n","\n"]},{"cell_type":"code","metadata":{"id":"apV6X-9Karem","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tS5MdBSBaret","colab_type":"code","colab":{}},"source":["!pip install gpustat\n","!gpustat"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXpFDB8darex","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","\n","device_lib.list_local_devices()"],"execution_count":0,"outputs":[]}]}