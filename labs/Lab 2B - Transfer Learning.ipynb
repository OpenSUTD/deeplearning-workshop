{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 2B - Transfer Learning.ipynb","version":"0.3.2","provenance":[{"file_id":"1z1U96GN66FkYS-vVtx3fl-Lyvr_TiS47","timestamp":1561810535270},{"file_id":"1bqE06VfVpNXtL0We-fbBEFO50BW450AJ","timestamp":1555169281814}],"collapsed_sections":["h7R_FcIPA1Ko"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"h7R_FcIPA1Ko","colab_type":"text"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"HTqhOE9jWQRc","colab_type":"code","colab":{}},"source":["!pip install tensorflow-gpu>=2.0b1 gpustat -qU"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOug94VRWWd0","colab_type":"code","outputId":"10d76d8d-a950-4e70-b837-a9e73a225181","executionInfo":{"status":"ok","timestamp":1564902428476,"user_tz":-480,"elapsed":6369,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh4.googleusercontent.com/-dGSoF3PTUms/AAAAAAAAAAI/AAAAAAAAEjo/onM3a4Ivxls/s64/photo.jpg","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","import tensorflow\n","\n","import tensorflow.compat.v2 as tf\n","import tensorflow.keras.layers as layers\n","import tensorflow_datasets as tfds"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0804 07:07:08.037279 140432171403136 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"oEi36ou7KySx","colab_type":"text"},"source":["# Transfer Learning with Keras"]},{"cell_type":"markdown","metadata":{"id":"WYijcApeY5R4","colab_type":"text"},"source":["In this notebook, we are going to be doing image classification on the [Kaggle \"Cats vs Dogs\" dataset](https://www.kaggle.com/c/dogs-vs-cats).\n","\n","However, we are not going to be training the model from scratch. Instead, we will be leveraging **transfer learning** to reduce the amount of time needed to train a very high accuracy model on a relatively small dataset.\n","\n","This notebook demonstrates a typical example of transfer learning where we take a model that has been trained on ImageNet, and fine-tune it for our own task."]},{"cell_type":"code","metadata":{"id":"KEiB77wqK1vy","colab_type":"code","outputId":"e8f78dca-fc9b-4259-a87b-121f6cc1177d","executionInfo":{"status":"ok","timestamp":1564902430504,"user_tz":-480,"elapsed":8392,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh4.googleusercontent.com/-dGSoF3PTUms/AAAAAAAAAAI/AAAAAAAAEjo/onM3a4Ivxls/s64/photo.jpg","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!gpustat"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[1m\u001b[37mf3644b6b817d       \u001b[m  Sun Aug  4 07:07:08 2019  \u001b[1m\u001b[30m410.79\u001b[m\n","\u001b[36m[0]\u001b[m \u001b[34mTesla T4        \u001b[m |\u001b[1m\u001b[31m 67'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m15079\u001b[m MB |\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AZieFWCpLUtO","colab_type":"text"},"source":["## Construct Input Pipeline"]},{"cell_type":"markdown","metadata":{"id":"eVgB1lohZu2l","colab_type":"text"},"source":["This section demonstrates how to build a high-performance input pipeline for feeding in training and evaluation data into the model."]},{"cell_type":"markdown","metadata":{"id":"z4O-FO1UaYeY","colab_type":"text"},"source":["### Load Dataset using TensorFlow Datasets\n","\n","\"Cats vs Dogs\" is not a standard research dataset, and is not found in `tf.keras.datasets` like the more common MNIST or CIFAR10. Fortunately, **TensorFlow Datasets** not only contains this dataset, but also many others. \n","\n","When we load datasets with TensorFlow Datasets, we get [`tf.data.Dataset`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset) objects. This means we automatically take advantage of high performance `tf.data` primitives to create highly-optimized, efficient input pipelines that result in better utilization of our hardware accelerators, such as GPUs or TPUs that might otherwise be constantly \"waiting\" for data from the CPU. This is important because hardware accelerators for deep learning are so fast, the speed at which we can feed images into the accelerator is usually a significant bottleneck. \n","\n","Using `tf.data` is a best practice (especially for reading large datasets). You can read more about using tf.data at the following links:\n","\n","* https://www.tensorflow.org/beta/guide/data\n","* https://www.tensorflow.org/guide/performance/datasets"]},{"cell_type":"code","metadata":{"id":"kf0vStKoaYCH","colab_type":"code","outputId":"8e91e79a-9790-4699-b581-3922bad575de","executionInfo":{"status":"ok","timestamp":1564902431580,"user_tz":-480,"elapsed":9459,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh4.googleusercontent.com/-dGSoF3PTUms/AAAAAAAAAAI/AAAAAAAAEjo/onM3a4Ivxls/s64/photo.jpg","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# define train-validation-test split\n","splits = tfds.Split.TRAIN.subsplit(weighted=(8, 1, 1))\n","\n","# load dataset with corresponding split\n","(raw_train, raw_validation, raw_test), info = tfds.load(\"cats_vs_dogs\",\n","                                                        split=list(splits),\n","                                                        with_info=True,\n","                                                        as_supervised=True)\n","\n","num_examples = info.splits[\"train\"].num_examples\n","num_train = int(num_examples * 0.8)\n","num_val = int(num_examples * 0.1)\n","num_test = int(num_examples * 0.1)\n","\n","print(\"Split:\", num_train, num_val, num_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Split: 18609 2326 2326\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WOy7hAFtcnaW","colab_type":"text"},"source":["### Build `tf.data` Pipeline"]},{"cell_type":"code","metadata":{"id":"6Ob-z76OwFQL","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 120\n","IMG_SIZE = (256, 256)\n","\n","@tf.function\n","def format_example(image, label):\n","    \"\"\"\n","    This function will run as part of a tf.data pipeline.\n","    It is reponsible for resizing and normalizing the input images.\n","    \"\"\"\n","    image = tf.cast(image, tf.float32)\n","    image = tf.image.resize(image, IMG_SIZE)\n","    image = (image/127.5) - 1\n","    return image, label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMD5_KhndBJK","colab_type":"text"},"source":["**Input Pipeline for Train Images**"]},{"cell_type":"code","metadata":{"id":"iMO6uEZPKmc-","colab_type":"code","colab":{}},"source":["train = raw_train.shuffle(4096)\n","train = train.repeat(count=-1)\n","train = train.map(format_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","train = train.batch(BATCH_SIZE)\n","train = train.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tgvLwbffdL9-","colab_type":"text"},"source":["**Input Pipeline for Validation and Test Images**\n","\n","We remove some unnecessary steps (like shuffling) and increase the batch size for faster inferencing."]},{"cell_type":"code","metadata":{"id":"bPxsljSkdMKC","colab_type":"code","colab":{}},"source":["val = raw_validation.repeat(count=-1)\n","val = val.map(format_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","val = val.batch(BATCH_SIZE*2)\n","val = val.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","test = raw_test.repeat(count=-1)\n","test = test.map(format_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","test = test.batch(BATCH_SIZE*2)\n","test = test.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUB3aSlaN0iH","colab_type":"text"},"source":["## Construct the Model"]},{"cell_type":"code","metadata":{"id":"7h0pyAF0L_EX","colab_type":"code","colab":{}},"source":["# you could also use other models like the following ResNet 50:\n","# from tensorflow.keras.applications.resnet50 import ResNet50\n","\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmMHAwp688E-","colab_type":"code","outputId":"b7455fda-2d6b-435a-c64d-4f6c3562961b","executionInfo":{"status":"ok","timestamp":1564902438333,"user_tz":-480,"elapsed":16192,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh4.googleusercontent.com/-dGSoF3PTUms/AAAAAAAAAAI/AAAAAAAAEjo/onM3a4Ivxls/s64/photo.jpg","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["input_layer = layers.Input(shape=(IMG_SIZE[0],IMG_SIZE[1],3,))\n","\n","base = MobileNetV2(input_tensor=input_layer, include_top=False, weights='imagenet')\n","\n","base.trainable = False\n","\n","x = base.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.2)(x)\n","preds = layers.Dense(2, activation=\"softmax\")(x)\n","\n","model = tf.keras.models.Model(inputs=input_layer, outputs=preds)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  warnings.warn('`input_shape` is undefined or non-square, '\n","W0804 07:07:11.347321 140432171403136 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"u90VRx_5NiS6","colab_type":"code","colab":{}},"source":["opt = tf.keras.optimizers.Adam(lr=0.001)\n","\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=opt,\n","              metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CpB3PSWgqTLw","colab_type":"text"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"id":"2zkA41zrd4YJ","colab_type":"code","outputId":"5f272463-a766-424f-ab14-0dd4436832b1","executionInfo":{"status":"ok","timestamp":1564902843837,"user_tz":-480,"elapsed":421687,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh4.googleusercontent.com/-dGSoF3PTUms/AAAAAAAAAAI/AAAAAAAAEjo/onM3a4Ivxls/s64/photo.jpg","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["model.fit(train, validation_data=val,\n","          validation_steps=num_val//BATCH_SIZE*2,\n","          steps_per_epoch=num_train//BATCH_SIZE,\n","          epochs=5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","155/155 [==============================] - 88s 567ms/step - loss: 0.1902 - acc: 0.9199 - val_loss: 0.1069 - val_acc: 0.9659\n","Epoch 2/5\n","155/155 [==============================] - 78s 501ms/step - loss: 0.0910 - acc: 0.9656 - val_loss: 0.1059 - val_acc: 0.9625\n","Epoch 3/5\n","155/155 [==============================] - 77s 499ms/step - loss: 0.0834 - acc: 0.9683 - val_loss: 0.0672 - val_acc: 0.9750\n","Epoch 4/5\n","155/155 [==============================] - 80s 516ms/step - loss: 0.0742 - acc: 0.9723 - val_loss: 0.0720 - val_acc: 0.9750\n","Epoch 5/5\n","155/155 [==============================] - 81s 522ms/step - loss: 0.0653 - acc: 0.9748 - val_loss: 0.0974 - val_acc: 0.9675\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb80a7e2a20>"]},"metadata":{"tags":[]},"execution_count":10}]}]}