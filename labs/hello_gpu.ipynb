{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hello_gpu.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yKcbbrwlarek","colab_type":"text"},"source":["# Hello, GPU!\n","\n","The graphics processing unit (GPU) is a powerful hardware acceleration card originally developed for 3D graphics. It is also ideal for various parallelizable workloads, common in machine learning and deep learning.\n","\n","There are a couple of possible GPUs that you might get assigned (for **free**!) on Google Colab. Roughly ranked in order of performance, they are:\n","\n","* P100\n","* T4 (rare)\n","* P4\n","* K80\n","\n","These server-grade GPUs (even the K80) are more powerful than most laptop or even desktop GPUs. The K80 is roughly equivalent to a GTX 1060 in training performance (~4 TFLOPS), but has much more memory (VRAM). The fastest card on the list, the P100, is slightly faster than a GTX 1080 Ti and has faster and more memory (16GB HBM2). The T4 can match a GTX 1080 Ti by using mixed precision.\n","\n","You can use the `nvidia-smi` command to check which GPU you are allocated.\n","\n"]},{"cell_type":"code","metadata":{"id":"apV6X-9Karem","colab_type":"code","outputId":"e2df0338-5680-4e52-f1e0-82a5f01edb32","executionInfo":{"status":"ok","timestamp":1577644034251,"user_tz":-480,"elapsed":8993,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCS8LwI0k0t2vkujQUBYfPPAo7627gWEnmKxe1ocA=s64","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sun Dec 29 18:27:10 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JxPZB-VE691Z","colab_type":"text"},"source":["You might see an error: `\n","NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running. `\n","\n","If you see the above error, please go to **Runtime > Change runtime type > Hardware accelerator** and select **GPU**."]},{"cell_type":"markdown","metadata":{"id":"HXZhBsEj6JUg","colab_type":"text"},"source":["You can also install and use other utilities like `gpustat` in the Colab environment"]},{"cell_type":"code","metadata":{"id":"tS5MdBSBaret","colab_type":"code","outputId":"38299c2d-bf26-413e-ef41-e447f2a9f6b1","executionInfo":{"status":"ok","timestamp":1577644050344,"user_tz":-480,"elapsed":25076,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCS8LwI0k0t2vkujQUBYfPPAo7627gWEnmKxe1ocA=s64","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["!pip install gpustat\n","!gpustat"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gpustat\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n","\r\u001b[K     |████▏                           | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 61kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.1MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.12.0)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat) (7.352.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat) (5.4.8)\n","Collecting blessings>=1.6\n","  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n","Building wheels for collected packages: gpustat\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpustat: filename=gpustat-0.6.0-cp36-none-any.whl size=12620 sha256=bd8bab9960b4b512117613843fbc6d61124afcaf3bcf96e681b6d702e2fd1898\n","  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n","Successfully built gpustat\n","Installing collected packages: blessings, gpustat\n","Successfully installed blessings-1.7 gpustat-0.6.0\n","\u001b[1m\u001b[37mbc94c57c4335           \u001b[m  Sun Dec 29 18:27:25 2019  \u001b[1m\u001b[30m418.67\u001b[m\n","\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[31m 40'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m16280\u001b[m MB |\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qZq7W5AW6OM9","colab_type":"text"},"source":["Here's an example of how you can check your GPU device via TensorFlow."]},{"cell_type":"code","metadata":{"id":"kXpFDB8darex","colab_type":"code","outputId":"4f266793-23f9-4907-8e95-8bb11fe64f22","executionInfo":{"status":"ok","timestamp":1577644053252,"user_tz":-480,"elapsed":27978,"user":{"displayName":"Timothy Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCS8LwI0k0t2vkujQUBYfPPAo7627gWEnmKxe1ocA=s64","userId":"03413426750796061565"}},"colab":{"base_uri":"https://localhost:8080/","height":550}},"source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","\n","device_lib.list_local_devices()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 12901138985227046086, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 6107419359804291040\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 897582802262704042\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 15956161332\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 16757169888688836939\n"," physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"]},"metadata":{"tags":[]},"execution_count":3}]}]}